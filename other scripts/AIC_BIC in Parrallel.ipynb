{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_aic(i):\n",
    "    #data = df.values\n",
    "    model = models[i]\n",
    "    bic = model.bic(shared_arr)\n",
    "    return bic\n",
    "def fit_bic(i):\n",
    "    #data = df.values\n",
    "    model = models[i]\n",
    "    aic = model.aic(shared_arr)\n",
    "    return aic\n",
    "\n",
    "def init(shared_arr_):\n",
    "    global shared_arr\n",
    "    shared_arr = shared_arr_\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    #num_processes = cpu_count()\n",
    "    p = Pool(2)\n",
    "    \n",
    "    init(df.values)\n",
    "    \n",
    "    print(np.shape(shared_arr))\n",
    "\n",
    "\n",
    "    try:\n",
    "        aic_values = p.map(fit_aic, range(len(models)))\n",
    "        bic_values = p.map(fit_bic, range(len(models)))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tonumpyarray(mp_arr):\n",
    "    return np.frombuffer(mp_arr.get_obj())\n",
    "\n",
    "def fit_aic(i):\n",
    "    #data = df.values\n",
    "    print(np.shape(np.reshape(tonumpyarray(shared_arr),orig_shape)))\n",
    "    model = models[i]\n",
    "    bic = model.bic(np.reshape(tonumpyarray(shared_arr),orig_shape))\n",
    "    return bic\n",
    "def fit_bic(i):\n",
    "    #data = df.values\n",
    "    model = models[i]\n",
    "    aic = model.aic(np.reshape(tonumpyarray(shared_arr),orig_shape))\n",
    "    return aic\n",
    "\n",
    "def tonumpyarray(mp_arr):\n",
    "    return np.frombuffer(mp_arr.get_obj())\n",
    "\n",
    "def init(shared_arr_):\n",
    "    global shared_arr\n",
    "    shared_arr = shared_arr_\n",
    "\n",
    "def main():\n",
    "    \n",
    "    shared_arr = Array(ctypes.c_double, len(np.ravel(df.values)))\n",
    "    arr = tonumpyarray(shared_arr)\n",
    "\n",
    "    arr[:] = np.ravel(df.values)\n",
    "    #arr_orig = arr.copy()\n",
    "    \n",
    "    orig_shape = np.shape(df.values)\n",
    "    \n",
    "    init(shared_arr)\n",
    "    \n",
    "    p = Pool(4)\n",
    "    \n",
    "    #p.map_async(fit_aic, )\n",
    "    \n",
    "    \n",
    "    out = p.map_async(fit_aic, [i for i in range(len(models))])\n",
    "        #pool.apply_async(extract_field_dict, (i, )\n",
    "    p.close()\n",
    "    p.join()\n",
    "    #processes = [Process(target=fit_aic, args=(i,)) for i in range(len(models))]\n",
    "    #for p in processes:\n",
    "    #    p.start()\n",
    "    #for p in processes:\n",
    "    #    p.join()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    shared_arr = Array(ctypes.c_double, len(np.ravel(df.values)))\n",
    "    arr = tonumpyarray(shared_arr)\n",
    "\n",
    "    arr[:] = np.ravel(df.values)\n",
    "    #arr_orig = arr.copy()\n",
    "    \n",
    "    orig_shape = np.shape(df.values)\n",
    "    \n",
    "    init(shared_arr)\n",
    "    \n",
    "    p = Pool(4)\n",
    "    \n",
    "    #p.map_async(fit_aic, )\n",
    "    \n",
    "    \n",
    "    out = p.map_async(fit_aic, [i for i in range(len(models))])\n",
    "        #pool.apply_async(extract_field_dict, (i, )\n",
    "    p.close()\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tonumpyarray(mp_arr):\n",
    "    return np.frombuffer(mp_arr.get_obj())\n",
    "\n",
    "shared_arr = Array(ctypes.c_double, len(np.ravel(df.values)))\n",
    "arr = tonumpyarray(shared_arr)\n",
    "\n",
    "# fill with random values\n",
    "arr[:] = np.ravel(df.values)\n",
    "arr_orig = arr.copy()\n",
    "\n",
    "\n",
    "def g(i):\n",
    "    \"\"\"no synchronization.\"\"\"\n",
    "    info(\"start %s\" % (i,))\n",
    "    arr = tonumpyarray(shared_arr)\n",
    "    arr[i] = -1 * arr[i]\n",
    "    info(\"end   %s\" % (i,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "  # allocate shared array - want lock=False in this case since we \n",
    "  # aren't writing to it and want to allow multiple processes to access\n",
    "  # at the same time - I think with lock=True there would be little or \n",
    "  # no speedup\n",
    "      maxLength = 50\n",
    "        toShare = Array('c', maxLength, lock=False)\n",
    "\n",
    "  # fork\n",
    "      pool = Pool()\n",
    "\n",
    "  # can set data after fork\n",
    "  testData = \"abcabcs bsdfsdf gdfg dffdgdfg sdfsdfsd sdfdsfsdf\"\n",
    "  if len(testData) > maxLength:\n",
    "      raise ValueError, \"Shared array too small to hold data\"\n",
    "  toShare[:len(testData)] = testData\n",
    "\n",
    "  print pool.map( count_it, [\"a\", \"b\", \"s\", \"d\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
